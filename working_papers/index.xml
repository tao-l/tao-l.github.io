<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Working Papers | </title>
    <link>https://tao-l.github.io/working_papers/</link>
      <atom:link href="https://tao-l.github.io/working_papers/index.xml" rel="self" type="application/rss+xml" />
    <description>Working Papers</description>
    <generator>Hugo Blox Builder (https://hugoblox.com)</generator><language>en-us</language><lastBuildDate>Mon, 29 Sep 2025 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://tao-l.github.io/media/icon_hu7729264130191091259.png</url>
      <title>Working Papers</title>
      <link>https://tao-l.github.io/working_papers/</link>
    </image>
    
    <item>
      <title>Information Design With Large Language Models</title>
      <link>https://tao-l.github.io/working_papers/info-llm-2025/</link>
      <pubDate>Mon, 29 Sep 2025 00:00:00 +0000</pubDate>
      <guid>https://tao-l.github.io/working_papers/info-llm-2025/</guid>
      <description>&lt;p&gt;Information design is typically studied through the lens of Bayesian signaling, where signals shape beliefs based on their correlation with the true state of the world. However, Behavioral Economics and Psychology emphasize that human decision-making is more complex and can depend on how information is framed. This paper formalizes a language-based notion of framing and bridges this to the popular Bayesian-persuasion model. We model framing as a possibly non-Bayesian, linguistic way to influence a receiver&amp;rsquo;s belief, while a signaling (or recommendation) scheme can further refine this belief in the classic Bayesian way. A key challenge in systematically optimizing in this framework is the vast space of possible framings and the difficulty of predicting their effects on receivers. Based on growing evidence that Large Language Models (LLMs) can effectively serve as proxies for human behavior, we formulate a theoretical model based on access to a framing-to-belief oracle. This model then enables us to precisely characterize when solely optimizing framing or jointly optimizing framing and signaling is tractable. We substantiate our theoretical analysis with an empirical algorithm that leverages LLMs to (1) approximate the framing-to-belief oracle, and (2) optimize over language space using a hill-climbing method. We apply this to two marketing-inspired case studies and validate the effectiveness through analytical and human evaluation.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Learning to Play Multi-Follower Bayesian Stackelberg Games</title>
      <link>https://tao-l.github.io/working_papers/personnat-learning-2025/</link>
      <pubDate>Sun, 28 Sep 2025 00:00:00 +0000</pubDate>
      <guid>https://tao-l.github.io/working_papers/personnat-learning-2025/</guid>
      <description></description>
    </item>
    
    <item>
      <title>WOMAC: A Mechanism For Prediction Competitions</title>
      <link>https://tao-l.github.io/working_papers/womac-2025/</link>
      <pubDate>Mon, 25 Aug 2025 00:00:00 +0000</pubDate>
      <guid>https://tao-l.github.io/working_papers/womac-2025/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Explainable Information Design</title>
      <link>https://tao-l.github.io/working_papers/exp-info-2025/</link>
      <pubDate>Tue, 19 Aug 2025 00:00:00 +0000</pubDate>
      <guid>https://tao-l.github.io/working_papers/exp-info-2025/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Learning to Coordinate Bidders in Non-Truthful Auctions</title>
      <link>https://tao-l.github.io/working_papers/fu-learning-2025/</link>
      <pubDate>Fri, 04 Jul 2025 00:00:00 +0000</pubDate>
      <guid>https://tao-l.github.io/working_papers/fu-learning-2025/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Learning a Game by Paying the Agents</title>
      <link>https://tao-l.github.io/working_papers/zhang-learning-2025/</link>
      <pubDate>Wed, 05 Mar 2025 00:00:00 +0000</pubDate>
      <guid>https://tao-l.github.io/working_papers/zhang-learning-2025/</guid>
      <description></description>
    </item>
    
  </channel>
</rss>
