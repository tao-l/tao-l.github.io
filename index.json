[{"authors":["admin"],"categories":null,"content":"I am a third-year PhD student in Computer Science at Harvard University, where I am very fortunate to be advised by Prof. Yiling Chen. My research interest lies in the intersection between economics and machine learning. I have been working on \u0026ldquo;mechanism design + machine learning\u0026rdquo; problems since my undergraduate study at Peking University, working with Prof. Xiaotie Deng. Recently, I started to look into information design problems like information aggregation, also from a machine learning perspective.\n","date":-62135596800,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"authors","summary":"I am a third-year PhD student in Computer Science at Harvard University, where I am very fortunate to be advised by Prof. Yiling Chen. My research interest lies in the intersection between economics and machine learning. I have been working on \u0026ldquo;mechanism design + machine learning\u0026rdquo; problems since my undergraduate study at Peking University, working with Prof. Xiaotie Deng. Recently, I started to look into information design problems like information aggregation, also from a machine learning perspective.","tags":null,"title":"Tao Lin","type":"authors"},{"authors":["Xiaotie Deng","Yotam Gafni","Ron Lavi","Tao Lin","Hongyi Ling"],"categories":null,"content":"","date":1676157050,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1676157050,"objectID":"17b399feb3f26223aa2998e7134cac27","permalink":"/publication/contest_competition/","publishdate":"2021-02-11T19:10:50-04:00","relpermalink":"/publication/contest_competition/","section":"publication","summary":"We study competition among contests in a general model that allows for an arbitrary and heterogeneous space of contest design and symmetric contestants. The goal of the contest designers is to maximize the contestants’ sum of efforts. Our main result shows that optimal contests in the monopolistic setting (i.e., those that maximize the sum of efforts in a model with a single contest) form an equilibrium in the model with competition among contests. Under a very natural assumption these contests are in fact dominant, and the equilibria that they form are unique. Moreover, equilibria with the optimal contests are Pareto-optimal even in cases where other equilibria emerge. In many natural cases, they also maximize the social welfare.","tags":["mechanism design","contest theory"],"title":"From Monopoly to Competition: Optimal Contests Prevail","type":"publication"},{"authors":[],"categories":[],"content":"","date":1675956573,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1675956573,"objectID":"a6ab42ad501cfe5f7290dcdbeda6ce90","permalink":"/content/","publishdate":"2023-02-09T10:29:33-05:00","relpermalink":"/content/","section":"","summary":"","tags":[],"title":"Content","type":"page"},{"authors":["Yiling Chen","Tao Lin"],"categories":null,"content":"","date":1675829839,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1675829839,"objectID":"644e992f44d71161f6f4106b34b7de5d","permalink":"/publication/persuasion/","publishdate":"2023-02-08T00:17:19-04:00","relpermalink":"/publication/persuasion/","section":"publication","summary":"The classic Bayesian persuasion model assumes a Bayesian and best-responding receiver. We study a relaxation of the Bayesian persuasion model where the receiver can approximately best respond to the sender's signaling scheme. We show that, under natural assumptions, (1) the sender can find a signaling scheme that guarantees itself an expected utility almost as good as its optimal utility in the classic model, no matter what approximately best-responding strategy the receiver uses; (2) on the other hand, there is no signaling scheme that gives the sender much more utility than its optimal utility in the classic model, even if the receiver uses the approximately best-responding strategy that is best for the sender. Together, (1) and (2) imply that the approximately best-responding behavior of the receiver does not affect the sender's maximal achievable utility a lot in the Bayesian persuasion problem. The proofs of both results rely on the idea of robustification of a Bayesian persuasion scheme: given a pair of the sender's signaling scheme and the receiver's strategy, we can construct another signaling scheme such that the receiver prefers to use that strategy in the new scheme more than in the original scheme, and the two schemes give the sender similar utilities. As an application of our main result (1), we show that, in a repeated Bayesian persuasion model where the receiver learns to respond to the sender by some algorithms, the sender can do almost as well as in the classic model. Interestingly, unlike (2), with a learning receiver the sender can sometimes do much better than in the classic model.","tags":["information design","machine learning","online learning"],"title":"Persuading a Behavioral Agent: Approximately Best Responding and Learning","type":"publication"},{"authors":["Tao Lin"],"categories":["notes"],"content":"","date":1670992894,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1670992894,"objectID":"b999cc4218c7e2b8d9f682e5f395561b","permalink":"/publication/sample-erm-product/","publishdate":"2021-10-11T00:41:34-04:00","relpermalink":"/publication/sample-erm-product/","section":"publication","summary":"While many classical notions of learnability (e.g., PAC learnability) are distribution-free, utilizing the specific structures of an input distribution may improve learning performance. For example, a product distribution on a multi-dimensional input space has a much simpler structure than a correlated distribution. A recent paper [GHTZ21] shows that the sample complexity of a general learning problem on product distributions is polynomial in the input dimension, which is exponentially smaller than that on correlated distributions. However, the learning algorithm they use is not the standard Empirical Risk Minimization (ERM) algorithm. In this note, we characterize the sample complexity of ERM in a general learning problem on product distributions. We show that, even though product distributions are simpler than correlated distributions, ERM still needs an exponential number of samples to learn on product distributions, instead of a polynomial. This leads to the conclusion that a product distribution by itself does not make a learning problem easier – an algorithm designed specifically for product distributions is needed.","tags":["machine learning","mechanism design"],"title":"How Does Independence Help Generalization? Sample Complexity of ERM on Product Distributions","type":"publication"},{"authors":["Yiling Chen","Tao Lin"],"categories":null,"content":"","date":1661401039,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1661401039,"objectID":"f5339dd65eeaf28731284282085f110e","permalink":"/publication/aggregation/","publishdate":"2022-08-25T00:17:19-04:00","relpermalink":"/publication/aggregation/","section":"publication","summary":"","tags":["information design","machine learning"],"title":"Sample Complexity of Forecast Aggregation","type":"publication"},{"authors":[],"categories":null,"content":"","date":1652140800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1652140800,"objectID":"002a7b5712aab136d754973be4a123c0","permalink":"/talk/nash-convergence/","publishdate":"2022-05-10T20:16:02-04:00","relpermalink":"/talk/nash-convergence/","section":"talk","summary":"","tags":[],"title":"Nash Convergence of Mean-Based Learning Algorithms in First Price Auctions","type":"talk"},{"authors":["Xiaotie Deng","Xinyan Hu","Tao Lin","Weiqiang Zheng"],"categories":null,"content":"","date":1648786656,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1648786656,"objectID":"1f9150ef595fe3f01f2d56cefbd12557","permalink":"/publication/fpa-convergence/","publishdate":"2021-10-11T00:17:36-04:00","relpermalink":"/publication/fpa-convergence/","section":"publication","summary":"Understanding the convergence properties of learning dynamics in repeated auctions is a timely and important question in the area of learning in auctions, with numerous applications in, e.g., online advertising markets.  This work focuses on repeated first price auctions where bidders with fixed values for the item learn to bid using mean-based algorithms -- a large class of online learning algorithms that include popular no-regret algorithms such as Multiplicative Weights Update and Follow the Perturbed Leader. We completely characterize the learning dynamics of mean-based algorithms, in terms of convergence to a Nash equilibrium of the auction, in two senses: (1) time-average: the fraction of rounds where bidders play a Nash equilibrium approaches 1 in the limit; (2) last-iterate: the mixed strategy profile of bidders approaches a Nash equilibrium in the limit.  Specifically, the results depend on the number of bidders with the highest value:\n- If the number is at least three, the bidding dynamics almost surely converges to a Nash equilibrium of the auction, both in time-average and in last-iterate.\n- If the number is two, the bidding dynamics almost surely converges to a Nash equilibrium in time-average but not necessarily in last-iterate.\n- If the number is one, the bidding dynamics may not converge to a Nash equilibrium in time-average nor in last-iterate.\nOur discovery opens up new possibilities in the study of convergence dynamics of learning algorithms.","tags":["mechanism design","auction theory","machine learning","online learning"],"title":"Nash Convergence of Mean-Based Learning Algorithms in First Price Auctions","type":"publication"},{"authors":["Manon Revel","Tao Lin","Daniel Halpern"],"categories":null,"content":"","date":1643689039,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1643689039,"objectID":"a2c42c6616e15e212469e2e319d56b0e","permalink":"/publication/congress/","publishdate":"2021-10-11T00:17:19-04:00","relpermalink":"/publication/congress/","section":"publication","summary":"We analyze the optimal size of a congress in a representative democracy. We take an epistemic view where voters decide on a binary issue with one ground truth outcome, and each voter votes correctly according to their competence levels in [0,1]. Assuming that we can sample the best experts to form an epistemic congress, we find that the optimal congress size should be linear in the population size. This result is striking because it holds even when allowing the top representatives to be accurate with arbitrarily high probabilities. We then analyze real world data, finding that the actual sizes of congresses are much smaller than the optimal size our theoretical results suggest. We conclude by analyzing under what conditions congresses of sub-optimal sizes would still outperform direct democracy, in which all voters vote.","tags":["social choice"],"title":"How Many Representatives Do We Need? The Optimal Size of an Epistemic Congress","type":"publication"},{"authors":[],"categories":null,"content":"","date":1608681600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1608681600,"objectID":"e3aa003e446f3ded3f189aff65b4663e","permalink":"/talk/erm-itcs/","publishdate":"2021-10-10T20:16:02-04:00","relpermalink":"/talk/erm-itcs/","section":"talk","summary":" Empirical Revenue Maximization (ERM) is an important price learning algorithm in data-driven auction design. It learns, from samples of bidders' value distribution, an approximately revenue optimal reservation price in both repeated auctions and uniform-price auctions.\n\nHowever, in these scenarios the bidders who provide samples to ERM have incentives to manipulate the samples in order to lower the output price.  We show that ERM is robust against such manipulation, as long as the number of manipulated samples is small.  Specifically, we generalize a measure called “incentive-awareness measure” proposed by Lavi et al (2019) to quantify the reduction of ERM’s output due to a change of 1 ≤ m≤ o(N^0.5) out of N input samples, and provide specific convergence rates of this measure to zero as N goes to infinity.  By adopting this measure, we use ERM to construct an efficient, approximately incentive-compatible, and revenue-optimal learning algorithm in repeated auctions against non-myopic bidders, and show approximate group-IC in uniform-price auctions.\n\nThis is joint work with Xiaotie Deng, Ron Lavi, Qi Qi, Wenwei Wang, Xiang Yan, accepted by NeurIPS’20 (see https://arxiv.org/abs/2010.05519 ) ","tags":[],"title":"Robustness of Empirical Revenue Maximization in Auction Learning","type":"talk"},{"authors":["Xiaotie Deng","Ron Lavi","Tao Lin","Qi Qi","Wenwei Wang","Xiang Yan"],"categories":null,"content":"","date":1607611952,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1607611952,"objectID":"19d55b0c068a74b61eb2024fc1330864","permalink":"/publication/erm/","publishdate":"2020-12-10T22:52:32+08:00","relpermalink":"/publication/erm/","section":"publication","summary":"The Empirical Revenue Maximization (ERM) is one of the most important price learning algorithms in auction design: as the literature shows it can learn approximately optimal reserve prices for revenue-maximizing auctioneers in both repeated auctions and uniform-price auctions. However, in these applications the agents who provide inputs to ERM have incentives to manipulate the inputs to lower the outputted price. We generalize the definition of an incentive-awareness measure proposed by Lavi et al (2019), to quantify the reduction of ERM's outputted price due to a change of m≥1 out of N input samples, and provide specific convergence rates of this measure to zero as N goes to infinity for different types of input distributions. By adopting this measure, we construct an efficient, approximately incentive-compatible, and revenue-optimal learning algorithm using ERM in repeated auctions against non-myopic bidders, and show approximate group incentive-compatibility in uniform-price auctions.","tags":["mechanism design","auction theory","machine learning"],"title":"A Game-Theoretic Analysis of the Empirical Revenue Maximization Algorithm with Endogenous Sampling","type":"publication"},{"authors":["Hu Fu","Tao Lin"],"categories":null,"content":"","date":1594874224,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1594874224,"objectID":"ec01e121dc144873baf4986dc674fb74","permalink":"/publication/fpa-sample/","publishdate":"2020-07-16T12:37:04+08:00","relpermalink":"/publication/fpa-sample/","section":"publication","summary":"In non-truthful auctions, agents' utility for a strategy depends on the strategies of the opponents and also the prior distribution over their private types; the set of Bayes Nash equilibria generally has an intricate dependence on the prior. Using the First Price Auction as our main demonstrating example, we show that Õ (n/ϵ^2) samples from the prior with n agents suffice for an algorithm to learn the interim utilities for all monotone bidding strategies. As a consequence, this number of samples suffice for learning all approximate equilibria. We give almost matching (up to polylog factors) lower bound on the sample complexity for learning utilities. We also consider a setting where agents must pay a search cost to discover their own types. Drawing on a connection between this setting and the first price auction, discovered recently by Kleinberg et al. (2016), we show that Õ (n/ϵ^2) samples suffice for utilities and equilibria to be estimated in a near welfare-optimal descending auction in this setting. En route, we improve the sample complexity bound, recently obtained by Guo et al. (2020), for the Pandora's Box problem, which is a classical model for sequential consumer search.","tags":["mechanism design","auction theory","machine learning"],"title":"Learning Utilities and Equilibria in Non-Truthful Auctions","type":"publication"},{"authors":["Xiaotie Deng","Tao Lin","Tao Xiao"],"categories":null,"content":"","date":1585408956,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1585408956,"objectID":"b0db6125d8ecbad0488fe0e43842da9c","permalink":"/publication/pdm/","publishdate":"2020-03-28T23:22:36+08:00","relpermalink":"/publication/pdm/","section":"publication","summary":"In this paper, we revisit the sponsored search auction as a repeated auction. We view it as a learning and exploiting task of the seller against the private data distribution of the buyers. We model such a game between the seller and buyers by a Private Data Manipulation (PDM) game: the auction seller first announces an auction for which allocation and payment rules are based on the value distributions submitted by buyers. The seller’s expected revenue depends on the design of the protocol and the game played among the buyers in their choice on the submitted (fake) value distributions. Under the PDM game, we re-evaluate the theory, methodology, and techniques in the sponsored search auctions that have been the most intensively studied in Internet economics.","tags":["mechanism design","auction theory"],"title":"Private Data Manipulation in Optimal Sponsored Search Auction","type":"publication"},{"authors":["Xiaoming Li","Tao Lin"],"categories":["notes"],"content":"","date":1575261694,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1575261694,"objectID":"3147338131b60ae16dbeeb3354bd6195","permalink":"/publication/market-clearing-price/","publishdate":"2021-10-11T00:41:34-04:00","relpermalink":"/publication/market-clearing-price/","section":"publication","summary":"Duality of linear programming is a standard approach to the classical weighted maximum matching problem. From an economic perspective, the dual variables can be regarded as prices of products and payoffs of buyers in a two-sided matching market. Traditional duality-based algorithms, e.g., Hungarian, essentially aims at finding a set of prices that clears the market. Under such market-clearing prices, a maximum matching is formed when buyers buy their most preferred products respectively. We study the property of market-clearing prices without the use of duality, showing that: (1) the space of market-clearing prices is convex and closed under element-wise maximum and minimum operations; (2) any market-clearing prices induce all maximum matchings.","tags":["matching market"],"title":"On Clearing Prices in Matching Markets: A Simple Characterization without Duality","type":"publication"},{"authors":[],"categories":[],"content":" This is a note about market-clearing prices in a matching market, where we prove that: (1) the space of market-clearing prices is convex; (2) the space of market-learning prices is closed under element-wise maximum and minimum operations; (3) any market-clearing prices induce all maximum matchings. We prove these claims using elementary mathematics, instead of using the classical yet opaque approach that relies on duality of linear programming.\n","date":1575235195,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1575235195,"objectID":"e65572fca46f3185a22eaeb296a9e844","permalink":"/post/market-clearing/","publishdate":"2019-12-01T16:19:55-05:00","relpermalink":"/post/market-clearing/","section":"post","summary":"This is a note about market-clearing prices in a matching market, where we prove that: (1) the space of market-clearing prices is convex; (2) the space of market-learning prices is closed under element-wise maximum and minimum operations; (3) any market-clearing prices induce all maximum matchings. We prove these claims using elementary mathematics, instead of using the classical yet opaque approach that relies on duality of linear programming.","tags":[],"title":"On Clearing Prices in Matching Markets: A Simple Characterization without Duality","type":"post"}]